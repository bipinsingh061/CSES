{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ronylpatil.ipynb",
      "provenance": [],
      "mount_file_id": "1eZfRvCniNVVCmWnqqrCzFbl2T6L-UIc_",
      "authorship_tag": "ABX9TyM041+8suwjO52t98mWzZ3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bipinsingh061/CSES/blob/main/Copy_of_ronylpatil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wOb7qZgwbEqV",
        "outputId": "e2462341-0ebf-4abb-c3e3-0597b3fe1690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal\n",
            "directory path : drive/MyDrive/coviddata2/archive/Dataset/Val/Normal\n",
            "test\n",
            "drive/MyDrive/coviddata2/archive/Dataset/Val/Normal/*.jpg\n",
            "test\n",
            "Covid\n",
            "directory path : drive/MyDrive/coviddata2/archive/Dataset/Val/Covid\n",
            "test\n",
            "drive/MyDrive/coviddata2/archive/Dataset/Val/Covid/*.jpg\n",
            "test\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "Covid\n",
            "directory path : drive/MyDrive/coviddata2/archive/Dataset/Train/Covid\n",
            "test\n",
            "drive/MyDrive/coviddata2/archive/Dataset/Train/Covid/*.jpg\n",
            "test\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "the loop works\n",
            "Normal\n",
            "directory path : drive/MyDrive/coviddata2/archive/Dataset/Train/Normal\n",
            "test\n",
            "drive/MyDrive/coviddata2/archive/Dataset/Train/Normal/*.jpg\n",
            "test\n",
            "{'Covid': 0}\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Accuracy :  1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Covid       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        11\n",
            "   macro avg       1.00      1.00      1.00        11\n",
            "weighted avg       1.00      1.00      1.00        11\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xray.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Architecture of Deep Hybrid Learning Model\n",
        "\"\"\"\n",
        "Project Name ->  Covid Detection using MRI's or CT Scan Images(Deep Hybrid Learning)\n",
        "Project Description -> Here in this project I am combining best of the both world's, one is traditional Machine Learning and Deep Learning to create a \n",
        "                       solution that works amazing well specially when we have limited training dataset. Here I used VGG16 pretrained network for \n",
        "                       extracting usefull features of image dataset and finally used XGBOOST for classifying the images.\n",
        "                       \n",
        "                       XGBoost is optimized version of gradient boosting and it is a much evolved version of random forest, actually XGBoost optimize speed \n",
        "                       and possibly accuracy. Suppose we don't have millions or thousands of images that required for deep learning then I found \n",
        "                       that the accuracy that I got with tens of images with XGBoost is far superior to what we would get with deep learning. \n",
        "                       So anytime if we work with limited data, always think about XGBoost as first option and if it doesn't work great then of \n",
        "                       course try deep learning. I am sure that sometime deep learning will not be enough if we have limited data. We can also \n",
        "                       engineer our own feature extractor but here I'm going to use VGG16 pretrained architecture which make it easy for us to extract these \n",
        "                       features without defining alot of code.\n",
        "                       \n",
        "                       At the end these fusion trained \n",
        "                       on 1000 MRI's or CT scans images (500 each COVID-19 & NORMAL) and finally achieved 98.32% accuracy and it took only 21.89 seconds to \n",
        "                       train this model. This fusion learning reduce the training time of our model, in general deep larning\n",
        "                       it usually takes a lot of time for training a model, but this hybrid technique reduced the training\n",
        "                       time and at the same time gave very good accuracy.\n",
        "Short Summary -> Image classification using XGBOOST by extracting features using VGG16 imagenet.\n",
        "                 This project explain the process of using XGBOOST for image classification using pretrained weights (VGG16) as feature extractors.\n",
        "        \n",
        "Folder Structure ->  \n",
        "                    X-ray       --> main folder\n",
        "                    ----| train      \n",
        "                        ----| COVID-19\n",
        "                            ----| img1.jpg\n",
        "                            ----| img2.jpg\n",
        "                            ----| img3.jpg\n",
        "                            ----| img4.jpg\n",
        "                        ----| NORMAL\n",
        "                            ----| img1.jpg\n",
        "                            ----| img2.jpg\n",
        "                            ----| img3.jpg\n",
        "                            ----| img4.jpg\n",
        "                    ----| test\n",
        "                        ----| COVID-19\n",
        "                            ----| img1.jpg\n",
        "                            ----| img2.jpg\n",
        "                            ----| img3.jpg\n",
        "                            ----| img4.jpg\n",
        "                        ----| NORMAL\n",
        "                            ----| img1.jpg\n",
        "                            ----| img2.jpg\n",
        "                            ----| img3.jpg\n",
        "                            ----| img4.jpg \n",
        "\"\"\"\n",
        "# train dataset : E:\\DHL Project\\CNN Projects\\Deep Hybrid Learning Projects\\X-ray\\train - 1000 units\n",
        "# test dataset : E:\\DHL Project\\CNN Projects\\Deep Hybrid Learning Projects\\X-ray\\test - 359 units\n",
        "\n",
        "# importing required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Creating static and local variables\n",
        "SIZE = 256\n",
        "SEED_TRAINING = 121\n",
        "SEED_TESTING = 197\n",
        "SEED_VALIDATION = 164\n",
        "CHANNELS = 3\n",
        "n_classes = 3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "input_shape = (SIZE, SIZE, CHANNELS)\n",
        "\n",
        "#--------------------Training\n",
        "def training(path) : \n",
        "    # loading data from local directory -> basic method. here labels are folder name, means each variety of data stored in particular folder.\n",
        "    train_images = []       # training dataset stored here...(numpy array form of images)\n",
        "    train_labels = []     # labels will be stored here \n",
        "    \n",
        "    '''here we are using glob for accessing directories'''\n",
        "    path = path + '/*'\n",
        "    for directory_path in glob.glob(path) :   \n",
        "        label = directory_path.split('/')[-1]       # taking labels from folders\n",
        "        print(label)    # extracting label from directory path #n\n",
        "        print(\"directory path : \"+directory_path) #n\n",
        "        '''now we are entering into each folder and reading images from it and at a same \n",
        "        time we are also storing the label.'''\n",
        "        print(\"test\")#n\n",
        "        newpath=os.path.join(directory_path,'*.jpg') #n\n",
        "        print(newpath) #n\n",
        "        print(\"test\") #n\n",
        "        # for img_path in glob.glob(os.path.join(directory_path, '*.JPG')) :\n",
        "        for img_path in glob.glob(newpath) :    \n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)    # read color image\n",
        "            print(\"the loop works\") #n\n",
        "            img = cv2.merge((img, img, img))      # we have grey scale image, here we are converting it into 3 channel image\n",
        "            img = cv2.resize(img, (SIZE, SIZE))        # resize the image\n",
        "            \n",
        "            '''actually cv2 read image in BGR channel ordering, in color image we have 3 channels\n",
        "            RGB so here the channel order is different nothing special!. it doesnt affect on model.\n",
        "            In reality we can arrange them in any order we like.'''\n",
        "            # cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            train_images.append(img)\n",
        "            train_labels.append(label)\n",
        "    \n",
        "    # Shuffling the list to avoid the some kind of bias.\n",
        "    train_data = list(zip(train_images, train_labels))\n",
        "    '''Seed function is used to save the state of a random function, so that it can generate          \n",
        "        same random numbers on multiple executions of the code on the same machine or on \n",
        "        different machines (for a specific seed value).'''\n",
        "    random.seed(SEED_TRAINING)   \n",
        "    random.shuffle(train_data)\n",
        "    train_images, train_labels = zip(*train_data)   # it will unzip the ziped iterators, it will return tuple\n",
        "    \n",
        "    # converting tuples to numpy array.\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = np.array(train_labels)\n",
        "    \n",
        "    # let's normalize our pixel values \n",
        "    train_images = train_images / 255.0\n",
        "    return train_images, train_labels\n",
        "\n",
        "def testing(path) : \n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "    \n",
        "    path = path + '\\*'\n",
        "    for directory_path in glob.glob(path) : \n",
        "        labels = directory_path.split('\\\\')[-1]\n",
        "        for img_path in glob.glob(os.path.join(directory_path, '*.JPG')) : \n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.merge((img, img, img)) \n",
        "            img = cv2.resize(img, (SIZE, SIZE))\n",
        "            test_images.append(img)\n",
        "            test_labels.append(labels)\n",
        "            \n",
        "    # Shuffling testing data\n",
        "    test_data = list(zip(test_images, test_labels))\n",
        "    random.seed(SEED_TESTING)\n",
        "    random.shuffle(test_data)\n",
        "    test_images, test_labels = zip(*test_data)\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = np.array(test_labels)\n",
        "    \n",
        "    # let's normalize our pixel values\n",
        "    test_images = test_images / 255.0\n",
        "    return test_images, test_labels\n",
        "\n",
        "# preprocessing training and testing images\n",
        "X_test, y_test_labels = training(r'drive/MyDrive/coviddata2/archive/Dataset/Val')\n",
        "X_train, y_train_labels = training(r'drive/MyDrive/coviddata2/archive/Dataset/Train')\n",
        "\n",
        "# encoding labels from text to integer\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_train_labels)\n",
        "train_label_encoded = le.transform(y_train_labels)\n",
        "le.fit(y_test_labels)\n",
        "test_label_encoded = le.transform(y_test_labels)\n",
        "\n",
        "# extracting original labels, later we will need it.\n",
        "labels = dict(zip(le.classes_,range(len(le.classes_))))\n",
        "print(labels)\n",
        "\n",
        "# aliasing for better understanding\n",
        "y_train, y_test = train_label_encoded, test_label_encoded\n",
        "\n",
        "# let's load VGG16 Architecture without fully connected layers, considerding only fully convolutional layers\n",
        "vgg_model = VGG16(weights = 'imagenet',  include_top = False, input_shape = (SIZE, SIZE, 3)) \n",
        "\n",
        "# let's make all layers non-trainable\n",
        "for layer in vgg_model.layers : \n",
        "    layer.trainable = False\n",
        "\n",
        "# now trainable parameter will be 0 in our architecture\n",
        "vgg_model.summary()\n",
        "\n",
        "# let's extract features from convolutional network for XBG\n",
        "feature_extractor = vgg_model.predict(X_train)\n",
        "\n",
        "# actually our data in the form of (1000, 8, 8, 512) into (1000, 8*8*512) \n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "X_train_features = features\n",
        "\n",
        "# perform same operation on test dataset\n",
        "feature_extractor_test = vgg_model.predict(X_test)\n",
        "features_test = feature_extractor_test.reshape(feature_extractor_test.shape[0], -1)\n",
        "X_test_features = features_test\n",
        "\n",
        "# defining XGBoost Classifier model\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_train_features, y_train)\n",
        "prediction = model.predict(X_test_features)\n",
        "\n",
        "# inversing le transforme to get original labels\n",
        "prediction = le.inverse_transform(prediction)\n",
        "\n",
        "# let's check overall accuracy\n",
        "print('Accuracy : ', metrics.accuracy_score(y_test_labels, prediction))\n",
        "\n",
        "# Confusion Matrics : Verify accuracy of each class\n",
        "cm = confusion_matrix(y_test_labels, prediction)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "sns.heatmap(cm, annot = True)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test_labels, prediction))\n",
        "\n",
        "# save the model\n",
        "joblib.dump(model, 'xray.pkl')\n",
        "\n",
        "# save model using pickle\n",
        "# import pickle\n",
        "# pickle.dump(model, open('modelp.pkl', 'wb'))"
      ]
    }
  ]
}